<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><html class="no-js"> <![endif]-->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Cassiopeia | Thành Nguyễn</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Be+Vietnam:wght@400;600&family=Jost:wght@400;600&display=swap">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/post-ux.css">
    <link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="manifest" href="site.webmanifest">
    <script src="https://code.jquery.com/jquery-3.5.1.js"></script>
    <script src="js/script.js"></script>
    <script src="js/modernizr-custom.js"></script>

</head>

<header>
    <nav>
        <div>
            <span class="switch"></span>
        </div>

        <div>
            <span class="icon-font-size-1"></span>
            <span class="icon-font-size-2"></span>
            <span class="icon-font-size-3"></span>
        </div>
        <div>
            <span class="icon-format_list_numbered"></span>
        </div>

    </nav>
    <div class="home">
        <a href="./">← Home</a>
    </div>
    <div class="scroll-to-top"><span class="icon-arrow-up2"></span></div>
    <div class="navigation-flyout">
        <ul>
            <li class="hyperlink anchor" id="anchor-development-process">Dev. Process</li>
            <li class="hyperlink anchor" id="anchor-problem-statement">Problem Statement</li>
            <li class="hyperlink anchor" id="anchor-core-user-needs">Core User Needs</li>
            <li class="hyperlink anchor" id="anchor-system-design">System Design</li>
            <li class="hyperlink anchor" id="anchor-user-flow">User Flow</li>
            <li class="hyperlink anchor" id="anchor-interface-design">Interface Design</li>
            <li class="hyperlink anchor" id="anchor-key-takeaways">Key Takeaways</li>
        </ul>
    </div>
</header>

<body>
    <!--[if lt IE 7]>
            <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="#">upgrade your browser</a> to improve your experience.</p>
        <![endif]-->

    <div class="card" id="cassiopeia">
        <div>
            <h2>Cassiopeia</h2>
            <h4>February 2020</h4>
        </div>
        <div class="desktop"></div>
    </div>

    <div class="flex">
        <div class="content">
            <section id="development-process">
                <h2>Development Process</h2>
                <br>
                <picture id="cassiopeia_design-process"></picture>
            </section>
            <hr>
            <section id="problem-statement">
                <h2>Problem Statement</h2>
                <p>During the master project at University of Bremen, we were required to collaborate with MaMBA at ZARM
                    to design and develop a piece of technology that is helpful for scientists on an extraterrestrial
                    mission.</p>
                <div class="icons">
                    <div>
                        <div>
                            <picture id="cassiopeia_constraints_small"></picture>
                            <p>Small-Sized Habitat</p>
                        </div>
                        <div>
                            <picture id="cassiopeia_constraints_slow"></picture>
                            <p>Slow Internet Connection</h4>
                        </div>
                    </div>
                    <div>
                        <div>
                            <picture id="cassiopeia_constraints_sad"></picture>
                            <p>Pronity to Mental Distress</p>
                        </div>
                        <div>
                            <picture id="cassiopeia_constraints_lab"></picture>
                            <p>Complex Laboratory Tasks</p>
                        </div>
                    </div>
                </div>
            </section>
            <hr>
            <section id="core-user-needs">
                <h2>Core User Needs</h2>
                <h4>Assistance with Laboratory Tasks</h4>
                <p>Conducting scientific experiments is a huge part of the mission. Life inside the habitat is
                    constrained enough without the frustrations from those laboratorial tasks, so the crew is in need of
                    an effective lab assistant which is smart enough to not perturb them.</p>
                <h4>Hands-Free Interaction</h4>
                <p>Lab experiments can escalate quickly, requiring a scientist to intensively use both of his hands to
                    handle it. In such cases, both paper-based and digital guidebooks don’t seem to help much as the
                    scientist can’t pause an on-going experiment to look up the instruction. Hands-free interaction is
                    an important feature while the user’s hands are busy.</p>
                <h4>Decentralization</h4>
                <p>There is an internet connection in the habitat, but the latency is bizarre! Theoretically, if one
                    needs to send a message from Mars to Earth, it will take approximately 20 minutes for the message to
                    reach the destination and vice-versa. In this case, the system needs to work offline or with an
                    unstable internet connection.</p>
                <h4>Intuitiveness</h4>
                <p>Because the crew is physically and virtually isolated from the rest of the world, they need to figure
                    out themselves how to use the system and how to fix it once it goes wrong. Therefore, intuitiveness
                    becomes one of the utmost important requirements of the system.</p>
                <h4>Compact Size</h4>
                <p>It’s not that spacious inside the habitat! The crew shared a story of them keeping playing with the
                    same board-games over and over because they couldn’t manage to bring more to the habitat. As a
                    result, the system needs to be compact and we should prioritize utilization of available devices in
                    the habitat.</p>
            </section>
            <hr>
            <section id="system-design">
                <h2>System Design</h2>
                <p>CASSIOPEIA serves as a compact decentralized voice assistant that enables crew members to select an
                    experiment they want to conduct and guides them through a predefined set of instructions of the
                    chosen experiment. The interaction channels are verbal input, visual and auditory output. </p>
                <p>The defined system comprises 4 vital components: the speech recognition module, the command execution
                    module, the text-to-speech module, and the graphical user interface.</p>
                <picture id="cassiopeia_system-architecture"></picture>
                <p>Central to our system is <b>SNIPS</b> – a freemium AI-powered on-device speech recognition service
                    (now
                    acquired by Sonos). This module requires some prior training to recognize what’s been said and its
                    intentions, then triggers one or more applets (within the command execution module) mapped to those
                    intentions.</p>
                <p>In the current use case, the applets are in charge of the information communication
                    channel between the database server (also within the command execution module), the text-to-speech
                    module, and the graphical user interface. </p>
                <p>As we tested the system, we discovered that SNIPS did a good job in recognizing phonology (sound of
                    the message), syntaxes (structure of the message), and semantics (logical meanings the message,
                    regardless of context), but it didn’t show much supports in pragmatics (contextual meanings of the
                    message).
                <blockquote>For example, by saying “I’m done” at the first step of an experiment, the crew members
                    intend to go on to the second step; however, at the end of an experiment, that could mean that they
                    want to successfully wrap up the experiment. </blockquote>
                <p>Having discovered that, we separated the user flow into
                    states, developed a state-machine accordingly, and applied it to the applets, so that SNIPS
                    “understands” the real intention of a command based on the context.</p>
                <p>The complementary GUI is a web-based application which acts as a pure visual output channel, i.e. no
                    point-and-touch interaction included.</p>
            </section>
            <hr>
            <section id="user-flow">
                <h2>User Flow</h2>
                <p>I – as an interaction designer – kept role-playing with other team members for hours (one as a crew
                    member and the other as the system) to figure out the most natural and intuitive way to guide the
                    crew members through the lengthy lab procedures. I figured out how lucky I was as the chosen use
                    case was more of a planned program than a free spontaneous talk, thus, it’s easier to predict which
                    actions will take place at a certain point in the user flow.</p>
                <picture>
                    <source srcset='images/cassiopeia_user-flow.webp' type='image/webp'>
                    <source srcset='images/cassiopeia_user-flow.png' type='image/png'>
                    <img src="images/cassiopeia_user-flow.png" alt="User Flow">
                </picture>

                <p>To maintain dialog consistency, we defined a couple of guidelines for the voice interface.</p>
                <ul>
                    <li>The dialog should work independently from the GUI, i.e. the crew members should be able to carry
                        out the whole procedure without the GUI, and the GUI shouldn’t give any extra information
                        compared to what the conversational interface provides.</li>
                    <li>The crew members need to always know where they currently are and what they just did in the
                        process, as well as which actions are available at the current state.</li>
                    <li>The crew members should always be able to ask the system to repeat the message, to cancel the
                        action, and to quit the current program. </li>
                    <li>During step-by-step instructions, the crew members should be able to navigate between the steps.
                    </li>
                    <li>Messages should be clear and as compact as possible which follow this order:</li>
                </ul>
                <picture>
                    <source srcset='images/cassiopeia_message-structure.webp' type='image/webp'>
                    <source srcset='images/cassiopeia_message-structure.png' type='image/png'>
                    <img src="images/cassiopeia_message-structure.png" alt="Message Structure">
                </picture>

                <p>You may now ask yourself why such important information like Content was pushed to the very end of
                    the message. The reason is actually simple: so that the crew member can remember it better! When the
                    short-term memory can’t hold up to the amount of information going in anymore, it becomes a
                    first-in-first-out queue, pushing the older information out to make space for the newer information.
                    Actually, we had internally tested our dialog with the main content being transmitted before the
                    instructions and observed quite a lot of distractions and confusion.</p>
            </section>
            <hr>
            <section id="interface-design">
                <h2>Interface Design</h2>
                <picture class="img-halfwidth">
                    <source srcset='images/cassiopeia_ui-preview.webp' type='image/webp'>
                    <source srcset='images/cassiopeia_ui-preview.png' type='image/png'>
                    <img src="images/cassiopeia_ui-preview.png" alt="UI Preview">
                </picture>

                <p>The GUI serves as a complementary output channel which, long story short, shows the crew members
                    what’s being said through the auditory output channel. It aims at solving the complications of the
                    conversational interface such as:</p>
                <ul>
                    <li>The crew members can’t remember which commands are available</li>
                    <li>Instruction’s complexity varies from a breeze to a headache, despite having been adjusted to be
                        on the (almost) same level</li>
                    <li>It can take forever to get the desired piece of information from the spoken message</li>
                </ul>
                <p>To tackle the mentioned problems, we started with building the wireframe together, then I instantly
                    created <a
                        href="https://www.figma.com/proto/sMP8xQaeBJupecp9TT7dpT/LoM?node-id=4%3A104&viewport=73%2C329%2C0.07611791789531708&scaling=min-zoom'"
                        class="hyperlink">this prototype</a> of the UI in Figma with the following features:</p>
                <ul>
                    <li>Large text and reasonable color contrast, so as to increase readability from a distance</li>
                    <li>Animated hint-bubbles, to show the available commands</li>
                    <li>Progress bar, during the step-by-step instruction</li>
                </ul>
                <p>The preliminary usability test showed huge improvements in terms of speed as well as accuracy of the
                    commands given to the system compared to the version coming without the GUI. All participants who
                    didn’t get the GUI shared that a GUI would have eased out the struggles they met during the test.
                </p>
                <picture class="img-halfwidth">
                    <source srcset='images/cassiopeia_help-bubble.webp' type='image/webp'>
                    <source srcset='images/cassiopeia_help-bubble.gif' type='image/gif'>
                    <img src="images/cassiopeia_help-bubble.gif" alt="UI Element: Help Bubble">
                </picture>
                <p>The hint-bubbles, however, seemed to give the test subjects a false restriction while giving
                    commands: they tended to wait until the hint appeared and say exactly what the hint tells them to
                    say, even though the system was capable of understanding more than what the hints showed. As a
                    result, we decided to change the order of the hints so that the most important hint is shown first,
                    so as to minimize the waiting time of the crew members. We also tried to adjust the wordings so that
                    it’s clear that the hints are suggestions, not restrictions.</p>
            </section>
            <hr>
            <section id="key-takeaways">
                <h2>Key Takeaways</h2>
                <p>We carried out a between-subject user study inside the lab module at MaMBA with
                    English-speaking
                    participants experienced in lab works. All of them have heard of Google Assistant or Amazon Alexa,
                    yet only 25% had experience with such technology. We utilized SUS/PSSUQ questionnaires and conducted
                    an interview with them
                    afterwards to analyze the usability of the system.</p>
                <h4>Multimodality Enhances Efficiency and Learnability</h4>
                <p>The complementary GUI became handy when it comes to long-to-very-long message transmission.
                    Participants interacting with the hybrid system (with the GUI) didn’t need to ask the system to
                    repeat the message that much in comparison to the pure conversational system, hence spent less time
                    finishing the lab procedure. We also found out that inexperienced participants get started quicker
                    when using the hybrid system.</p>
                <h4>Front-Facing Output Is Preferred</h4>
                <p>All participants seemed to turn towards the display/audio source while interacting with the system
                    even though it’s technically okay to do otherwise. They shared that they prefer front-facing audio
                    and graphical output or, at least, the display should be directly in front of them when they do the
                    job. This shows their habits while communicating–regardless of with whom–and a slight dependency on
                    the graphical interface.</p>
                <h4>Audio Quality Is Important</h4>
                <p>In the case of a voice assistant, the voice of the text-to-speech engine and the quality of the
                    speaker play a big role in determining user experience (similar to the case of devices with a
                    display where UI design and the quality of the display are important). This includes the pace of the
                    conversation, accent, intonation, pauses and stops, and how “natural” the speech engine is.</p>
            </section>
        </div>
        <div class="content-table desktop">
            <div>
                <h4>tl;dr</h4>
                <p>We designed and developed Cassiopeia – an intelligent lab assistant for extraterrestrial missions.
                </p>
            </div>
            <div>
                <h4>Roles</h4>
                <p>UI/UX Designer</p>
                <p>Middleware & Back-end Developer</p>
                <p>Project Co-Manager</p>
            </div>
            <ul class="anchors">
                <h4>Contents</h4>
                <li class="anchor" id="anchor-development-process">Dev. Process</li>
                <li class="anchor" id="anchor-problem-statement">Problem Statement</li>
                <li class="anchor" id="anchor-core-user-needs">Core User Needs</li>
                <li class="anchor" id="anchor-system-design">System Design</li>
                <li class="anchor" id="anchor-user-flow">User Flow</li>
                <li class="anchor" id="anchor-interface-design">Interface Design</li>
                <li class="anchor" id="anchor-key-takeaways">Key Takeaways</li>
            </ul>
        </div>
    </div>
    <div class="prev-next-posts">
        <a href="./" class="hyperlink-2">← Previous: Home</a>
        <a href="hashtag" class="hyperlink">Next: Hashtag Inspector →</a>
    </div>

</body>
<footer>

    <h4>© 2020 Thanh Nguyen</h4>
    <a href="https://dribbble.com/itsthanhnguyen/"><span class="icon-dribbble"></span></a>
    <a href="https://www.linkedin.com/in/thanh-nguyen-52112aa2/"><span class="icon-linkedin"></span></a>
    <a href="https://www.xing.com/profile/Thanh_Nguyen135/"><span class="icon-xing"></span></a>
    <a href="mailto:itsthanhng@gmail.com?subject=Hello!"><span class="icon-mail"></span></a>
</footer>

</html>