<!DOCTYPE html>
<html>

<head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="images/safari-pinned-tab.svg" color="#CE3739">
    <meta name="msapplication-TileColor" content="#CE3739">
    <meta name="theme-color" content="#ffffff">
    <title>Thành Nguyễn - CASSIOPEIA</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="CASSIOPEIA, designed and developed during my 4-month Master Project at the University of Bremen, is a functioning prototype of a laboratory assistant for scientists in the scope of extraterrestrial missions, in this case, Mars missions. For more information, please contact me at chithanh1811@gmail.com">
    <meta name="keywords" content="
		Portfolio,
		Design,
		Graphic Design,
		Interaction Design,
		UI Design,
		UX Design,
		UI UX Design,
		User Interface,
		User Experience,
		App Design,
		App UI Design,
		Interface Design,
		GUI Design,
		Gallery,
		Collection,
		Prototype,
		App Prototype,
		Thanh,
		Nguyen,
		Thanh Nguyen,
		Vietnam,
		Viet Nam
		">
    <meta name="author" content="Thanh Nguyen">
    <meta name="google-site-verification" content="E6QeVL9JHdZcgQxPsaqM1ojHUCcwliaMXWdHzzKU5TE">

    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/pure-min.css" integrity="sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47" crossorigin="anonymous">
    <link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css">
    <link rel="stylesheet" href="CSS/style-post.css">

    <link href="https://fonts.googleapis.com/css2?family=Jost:wght@400;600&display=swap" rel="stylesheet">

    <script src="https://kit.fontawesome.com/d81e4d454f.js" crossorigin="anonymous"></script>
    <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
    <script type="text/javascript" src="JS/script-post.js"></script>

</head>
<header>
    <div class="navigation">
        <div>
            <a href="https://chithanhnguyen.github.io" class="logo">
                <p class="extrabold">Home &#x1f448</p>
            </a>
            <div class="links desktop">
                <a class="hyperlink">Résumé</a>
                <a class="switch hyperlink">LIGHT OFF</a>
            </div>
            <div class="links mobile menu">
                <a class="hyperlink">Résumé</a>
                <a class="switch hyperlink">LIGHT OFF</a>
                <i class="fas fa-bars"></i>
            </div>
        </div>
    </div>
</header>
<body id="home">
    <div>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1 centered">
                    <img src="images/cassiopeia_featured-image.webp" style="max-width: 30vw; min-width: 15rem;"></img>
                </div>
            </div>
            <br></br>
            <div class="tag-container pure-g centered">
                <div>
                    <p class="tag red pure-u-1 pure-u-lg-1-4">Product Design</p>
                </div>
                <div>
                    <p class="tag blue pure-u-1 pure-u-lg-1-4">Interaction Design</p>
                </div>
                <div>
                    <p class="tag green pure-u-1 pure-u-lg-1-4">Visual Design</p>
                </div>
                <div>
                    <p class="tag purple pure-u-1 pure-u-lg-1-4">Development</p>
                </div>
            </div>
            <div class="pure-g">
                <div class="pure-u-1 centered">
                    <h1>CASSIOPEIA</h1>
                </div>
            </div>
        </section>
        <section class="grey">
            <div class="pure-g" id="main">
                <div class="pure-u-1">
                    <h2>ROLES</h2>
                </div>
                <div class="pure-u-1 pure-u-lg-1-2">
                    <p class="extrabold">Product Designer</p>
                    <p>Interaction Design</p>
                    <p>Visual Design</p>
                    <p>Prototyping</p>
                    <p>Testing</p>
                    <br></br>
                    <p class="extrabold">Marketer</p>
                    <p>Graphic Design</p>
                    </p>
                    <p>Technical Writing</p>
                </div>
                <div class="pure-u-1 pure-u-lg-1-2">
                    <br></br>
                    <p class="extrabold">Developer</p>
                    <p>Tech Research & Support</p>
                    <p>Middleware Developer</p>
                    <p>Back-end Developer</p>
                    <br></br>
                    <p class="extrabold">Project Co-manager</p>
                    <p>Meeting Moderator (Brainstorming & Retrospective)</p>
                    </p>
                    <p>Sprint Planning</p>
                </div>
            </div>
        </section>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1 pure-u-lg-1-2">
                    <h2>BACKGROUND</h2>
                    <p>CASSIOPEIA, designed and developed during my 4-month Master Project at the University of Bremen, is a functioning prototype of a laboratory assistant for scientists in the scope of extraterrestrial missions, in this case, Mars missions.
                        The original requirement was to design and develop a piece of technology that is helpful for such missions.</p>
                    <p>The development team for CASSIOPEIA is composed of 6 Digital Media students, most of whom are software developers.</p>
                </div>
                <div class="pure-u-1 pure-u-lg-1-2">
                    <h2>RESULTS</h2>
                    <p>We came up with our solution – CASSIOPEIA – an AI and voice-powered lab assistant, designed according to the requirements and constraints of the extraterrestrial habitat. It features:</p>
                    <ul>
                        <li>State-of-the-art voice recognition technology</li>
                        <li>Human-like output messages</li>
                        <li>A tailored graphical user interface</li>
                    </ul>
                </div>
            </div>
        </section>
        <section class="grey">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>PROBLEM-SOLVING APPROACH</h2>
                    <div class="expandable"><img src="images/cassiopeia_design-process.webp"></img></div>
                </div>
            </div>
        </section>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>DISCOVER</h2>
                    <p>At the beginning of the project, we had a chance to talk to a scientist who has been on a 366-day mission in the Hawaii Space Exploration Analog and Simulation (HI-SEAS) to get to know the lifestyle, the needs, and the constraints
                        inside the habitat, because it was nearly impossible for us to imagine a piece of technology that can be helpful in such an exotic setting.</p>
                    <p>And, we were right! The situation “up” there was no way to be predicted if one has never been in such surroundings:</p>
                </div>
                <div class="pure-u-1 pure-u-lg-1-2">
                    <img src="images/cassiopeia_mamba.webp"></img>
                </div>
                <div class="pure-u-1 pure-u-lg-1-2">
                    <ul>
                        <li>There is internet in the habitat, but the latency is bizarre! Theoretically, if one needs to send a message from Mars to Earth, it will take approximately 20 minutes for the message to reach the destination and vice-versa.</li>
                        <li>The crew members are isolated from the rest of the world (of course, unless one could befriend the aliens!) They must get on well with each other, or at least, minimize the frustration within the habitat, so as not to develop any
                            mental distress during the mission.
                        </li>
                        <li>It’s not that spacious inside the habitat!</li>
                        <li>Conducting scientific experiments is a huge part of the mission, and they can be really complicated.
                        </li>
                    </ul>
                </div>
            </div>
        </section>
        <section class="grey">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>IDEATION & EXPLORATION</h2>
                    <p>Having all the discovered facts at the back of our mind, we dug into research papers, case studies, and commercial products relevant to our context to come to the decision to create a digital “buddy” for the crew members.</p>
                    <p>I organized a 1-hour brainstorming workshop to explore the term “buddy” and narrow them down into an MVP (minimum viable product). Every team member was provided with a pen, sticky notes, and 5 minutes to think of the features that
                        our buddy should offer (crazy ideas are very welcomed).
                    </p>
                    <p>We collected more than 110 individual ideas coming in all forms, from writings to sketches. The notes were then sorted into the following categories:</p>
                </div>
            </div>
            <div class="pure-g">
                <div class="pure-u-1 pure-u-md-1-4 centered">
                    <p class="sticky-note-pink">The ability to listen and respond to the crew members</p>
                </div>
                <div class="pure-u-1 pure-u-md-1-4 centered">
                    <p class="sticky-note-green">Human-like companion with avatar and/or facial expressions</p>
                </div>
                <div class="pure-u-1 pure-u-md-1-4 centered">
                    <p class="sticky-note-yellow">The ability to display and/or project its content</p>
                </div>
                <div class="pure-u-1 pure-u-md-1-4 centered">
                    <p class="sticky-note-red">Look-and-feel & physical design (compact, mountable, etc...)</p>
                </div>
            </div>
            <div class="pure-g">
                <div class="pure-u-1 pure-u-md-1-3 centered">
                    <p class="sticky-note-beige">Configuration (offline-working mode, etc...)</p>
                </div>
                <div class="pure-u-1 pure-u-md-1-3 centered">
                    <p class="sticky-note-pink">Use-cases (emotional support, instruction, smart home, entertainment)
                    </p>
                </div>
                <div class="pure-u-1 pure-u-md-1-3 centered">
                    <p class="sticky-note-green">Individualizability & Communication between the instances</p>
                </div>
            </div>
        </section>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>SYSTEM DESIGN</h2>
                    <p>Considering the time and workforce constraints, we decided to go with the divide-and-conquer approach – we divided ourselves into 2 subteams, one team focuses on the “emotion” modules, and our team focused on the “instruction” use
                        case with the MVP described as follow:</p>
                    <p class="textbox">CASSIOPEIA serves as a compact offline voice assistant that enables crew members to select an experiment they want to conduct and guides them through a predefined set of instructions of the chosen experiment. The interaction channels
                        are verbal input, visual and auditory output.</p>
                    <p>The defined system comprises 4 vital components: the voice recognition module, the command execution module, the text-to-speech module, and the graphical user interface. After testing several potential options, we utilized SNIPS which
                        provides a freemium AI-powered on-device speech recognition and text-to-speech services; on the other hand, developing the handler code for SNIPS was not that complicated either. The complementary graphical user interface is a
                        web-based solution with an always-on communication channel with the handler code.</p>
                        <div class="expandable"><img src="images/cassiopeia_system-architecture.webp"></img></div>
                </div>
            </div>
        </section>
        <section class="grey">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>DIALOG DESIGN (USER FLOW)</h2>
                    <p>Rita and I – the Dialog Designers – kept role-playing between ourselves for hours (one as a crew member and the other as the system) to figure out the most natural way to guide the crew members through the lengthy procedures from starting
                        the application to selecting and following the instructions. While jotting down all the possible steps the crew members can take at each point of the flow, we figured out how lucky we were because the use case chosen to be developed
                        was more of a predictable use case than a free spontaneous talk. To maintain dialog consistency (as well as our smooth teamwork!), we defined a couple of guidelines for the conversational interface.
                    </p>
                    <ul>
                        <li>The dialog should work independently, regardless of the complementary GUI;</li>
                        <li>The GUI shouldn’t give any extra information compared to the conversational interface;</li>
                        <li>The crew members need to know where they currently are and what they just did in the process;
                        </li>
                        <li>The crew members should always have access to the manual provided through the conversational interface;
                        </li>
                        <li>The crew members should always be able to ask the system to repeat the message;</li>
                        <li>Canceling should always be possible;</li>
                        <li>During step-by-step instructions, going back and forth between the steps should be possible;
                        </li>
                        <li>Messages should be clear, yet as compact as possible;</li>
                        <li>Messages must follow this order:</li>
                    </ul>
                    <div class="expandable"><img src="images/cassiopeia_message-structure.webp"></img></div>
                    <p>You may now ask yourself why the Content – the most important information – was pushed to the very end of the message. The reason is actually simple: so that the crew member can remember it better! When the short-term memory can’t
                        hold up to the amount of information going in anymore, it becomes a first-in-first-out queue, pushing the older information out to make space for the newer information. Actually, we had also tested our dialog with the main content
                        being pushed to the beginning and observed quite a lot of distractions and confusion.</p>
                    <p>Alongside the guidelines, we also created a flowchart that became really useful for the design of the UI as well as the implementation process.</p>
                </div>
            </div>
        </section>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>UI DESIGN</h2>
                    <div class="expandable"><img src="images/cassiopeia_ui-preview.webp"></img></div>
                    <p>The GUI serves as a complementary output channel which, long story short, shows the crew members what’s being said through the auditory output channel. It aims at solving the complications of the conversational interface such as:</p>
                    <ul>
                        <li>The crew members can’t remember which commands are available;</li>
                        <li>Instruction’s complexity varies from a breeze to a headache, despite having been adjusted to be on the (almost) same level;</li>
                        <li>It can take forever to get the desired piece of information from the spoken message.</li>
                    </ul>
                    <p>To tackle the mentioned problems, I instantly created <a href="https://www.figma.com/proto/sMP8xQaeBJupecp9TT7dpT/LoM?node-id=4%3A104&viewport=73%2C329%2C0.07611791789531708&scaling=min-zoom" class="hyperlink">this
							prototype</a> of the UI in Figma with the following features:</p>
                    <ul>
                        <li>Large-enough font size and reasonable color contrast, so as to increase readability from a distance
                        </li>
                        <li>Animated hint-bubbles, to show the available commands</li>
                        <li>Progress bar, during the step-by-step instruction</li>
                    </ul>

                    <p>The preliminary usability test showed huge improvements in terms of speed as well as accuracy of the commands given to the system compared to the version coming without the GUI. All the people who didn’t get the GUI shared that a GUI
                        would have eased out the process without knowing that the GUI were available.</p>
                    <img src="images/cassiopeia_help-bubble.webp" style="max-width: 30vw; min-width: 15rem; display: block; margin-left: auto; margin-right: auto;"></img>
                    <p>The hint-bubbles, however, seemed to give the test subjects a false restriction while giving commands: they tended to wait until the hint appears and say exactly what the hint tells them to say, even though the system was capable of
                        understanding more than what the hints showed. As a result, we decided to change the order of the hints so that the most important hint is shown first, so as to minimize the waiting time of the crew members. We also tried to adjust
                        the wordings so that it’s clear that the hints are suggestions, not restrictions.</p>
                </div>
            </div>
        </section>
        <section class="grey">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>DEVELOPMENT</h2>
                    <p>Our chosen library – SNIPS – supports several well-known platforms such as Android, iOS, Raspberry Pi, and Debian. During the exploration phase, I decided to organize several internal workshops on Debian OS and basic Android Development
                        (with Java), so that everyone in the team had the chance to explore and learn the logic behind the technology themselves while I dug deeper into installation and coding. Although we chose to go with Python and Raspberry Pi later
                        on, it was worth it to explore the technology on Android because Android development for SNIPS was a breeze and (almost) everyone has their own Android device to test. Besides, there wasn’t that much of the difference between the
                        syntaxes in Java and Python.</p>
                    <p>In fact, SNIPS did a good job in recognizing phonology (sound of the message), syntaxes (structure of the message), and semantics (logical meanings the message, regardless of context), but it didn’t show much supports in pragmatics
                        (contextual meanings of the message).</p>
                    <p>As we tested the system, we discovered quite a lot of problems where SNIPS triggered the wrong actions even though the commands were legit - because it didn’t take the context into consideration. For example, by saying “Let’s end it!”
                        at the first step of an experiment, the crew members intend to quit the experiment prematurely; however, if they say it at the end of an experiment, they might just want to successfully wrap up the experiment. Having discovered
                        that, I separated the dialog flow into states, developed a state-machine accordingly, and applied it to the handler code, so that SNIPS “understands” the real intention of a command based on the context.
                    </p>
                </div>
            </div>
        </section>
        <section class="white">
            <div class="pure-g">
                <div class="pure-u-1">
                    <h2>USABILITY TEST</h2>
                    <p>The final usability tests will take place from February 18th to 21st, and the results as well as the findings will be updated as soon as they arrive!</p>
                </div>
            </div>
        </section>
    </div>

    <div class="scroll overlay">
        <i class="fas fa-chevron-up"></i>
    </div>

</body>
<footer>
    <div class="social-icons">
        <a href="https://dribbble.com/itzthahnngurn/"><i class="fab fa-dribbble"></i></a>
        <a href="https://www.linkedin.com/in/thanh-nguyen-52112aa2/"><i class="fab fa-linkedin-in"></i></a>
        <a href="https://www.xing.com/profile/Thanh_Nguyen135/"><i class="fab fa-xing"></i></a>
        <a href="mailto:chithanh1811@gmail.com?subject=Hello!"><i class="fas fa-envelope-open"></i></a>
    </div>
    <div>© 2020 Thanh Nguyen. Made from scratch with lots of &#x2764, Google, and StackOverflow.</div>  
</footer>

</html>